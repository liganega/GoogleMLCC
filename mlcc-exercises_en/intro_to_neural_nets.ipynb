{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "wDlWLbfkJtvu"
   },
   "outputs": [],
   "source": [
    "#@title Copyright 2020 Google LLC. Double-click here for license information.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL5y5fY9Jy_x"
   },
   "source": [
    "# Introduction to Neural Nets\n",
    "\n",
    "This Colab builds a deep neural network to perform more sophisticated linear regression than the earlier Colabs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RDY3EeAluPd"
   },
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "After doing this Colab, you'll know how to do the following:\n",
    "\n",
    "  * Create a simple deep neural network.\n",
    "  * Tune the hyperparameters for a simple deep neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGj0PNaJlubZ"
   },
   "source": [
    "## The Dataset\n",
    "  \n",
    "Like several of the previous Colabs, this Colab uses the [California Housing Dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tX_umRMMsa3z"
   },
   "source": [
    "## Use the right version of TensorFlow\n",
    "\n",
    "The following hidden code cell ensures that the Colab will run on TensorFlow 2.X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "lM75uNH-sTv2"
   },
   "outputs": [],
   "source": [
    "#@title Run on TensorFlow 2.x\n",
    "#%tensorflow_version 2.x\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xchnxAsaKKqO"
   },
   "source": [
    "## Import relevant modules\n",
    "\n",
    "The following hidden code cell imports the necessary code to run the code in the rest of this Colaboratory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "9n9_cTveKmse"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported modules.\n"
     ]
    }
   ],
   "source": [
    "#@title Import relevant modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "print(\"Imported modules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_TaJhU4KcuY"
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "Like most of the previous Colab exercises, this exercise uses the California Housing Dataset.  The following code cell loads the separate .csv files and creates the following two pandas DataFrames:\n",
    "\n",
    "* `train_df`, which contains the training set\n",
    "* `test_df`, which contains the test set\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZlvdpyYKx7V"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index)) # shuffle the examples\n",
    "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ldP-5z1B2vL"
   },
   "source": [
    "## Normalize values\n",
    "\n",
    "When building a model with multiple features, the values of each feature should cover roughly the same range.  The following code cell normalizes datasets by converting each raw value to its Z-score. (For more information about Z-scores, see the Classification exercise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "g8HC-TDgB1D1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized the values.\n"
     ]
    }
   ],
   "source": [
    "#@title Convert raw values to their Z-scores \n",
    "\n",
    "# Calculate the Z-scores of each column in the training set:\n",
    "train_df_mean = train_df.mean()\n",
    "train_df_std = train_df.std()\n",
    "train_df_norm = (train_df - train_df_mean)/train_df_std\n",
    "\n",
    "# Calculate the Z-scores of each column in the test set.\n",
    "test_df_mean = test_df.mean()\n",
    "test_df_std = test_df.std()\n",
    "test_df_norm = (test_df - test_df_mean)/test_df_std\n",
    "\n",
    "print(\"Normalized the values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b9ehCgIRjTxy"
   },
   "source": [
    "## Represent data\n",
    "\n",
    "The following code cell creates a feature layer containing three features:\n",
    "\n",
    "* `latitude` X `longitude` (a feature cross)\n",
    "* `median_income`\n",
    "* `population`\n",
    "\n",
    "This code cell specifies the features that you'll ultimately train the model on and how each of those features will be represented. The transformations (collected in `my_feature_layer`) don't actually get applied until you pass a DataFrame to it, which will happen when we train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8EkNAQhnjSu-"
   },
   "outputs": [],
   "source": [
    "# Create an empty list that will eventually hold all created feature columns.\n",
    "feature_columns = []\n",
    "\n",
    "# We scaled all the columns, including latitude and longitude, into their\n",
    "# Z scores. So, instead of picking a resolution in degrees, we're going\n",
    "# to use resolution_in_Zs.  A resolution_in_Zs of 1 corresponds to \n",
    "# a full standard deviation. \n",
    "resolution_in_Zs = 0.3  # 3/10 of a standard deviation.\n",
    "\n",
    "# Create a bucket feature column for latitude.\n",
    "latitude_as_a_numeric_column = tf.feature_column.numeric_column(\"latitude\")\n",
    "latitude_boundaries = list(np.arange(int(min(train_df_norm['latitude'])), \n",
    "                                     int(max(train_df_norm['latitude'])), \n",
    "                                     resolution_in_Zs))\n",
    "latitude = tf.feature_column.bucketized_column(latitude_as_a_numeric_column, latitude_boundaries)\n",
    "\n",
    "# Create a bucket feature column for longitude.\n",
    "longitude_as_a_numeric_column = tf.feature_column.numeric_column(\"longitude\")\n",
    "longitude_boundaries = list(np.arange(int(min(train_df_norm['longitude'])), \n",
    "                                      int(max(train_df_norm['longitude'])), \n",
    "                                      resolution_in_Zs))\n",
    "longitude = tf.feature_column.bucketized_column(longitude_as_a_numeric_column, \n",
    "                                                longitude_boundaries)\n",
    "\n",
    "# Create a feature cross of latitude and longitude.\n",
    "latitude_x_longitude = tf.feature_column.crossed_column([latitude, longitude], hash_bucket_size=100)\n",
    "crossed_feature = tf.feature_column.indicator_column(latitude_x_longitude)\n",
    "feature_columns.append(crossed_feature)  \n",
    "\n",
    "# Represent median_income as a floating-point value.\n",
    "median_income = tf.feature_column.numeric_column(\"median_income\")\n",
    "feature_columns.append(median_income)\n",
    "\n",
    "# Represent population as a floating-point value.\n",
    "population = tf.feature_column.numeric_column(\"population\")\n",
    "feature_columns.append(population)\n",
    "\n",
    "# Convert the list of feature columns into a layer that will later be fed into\n",
    "# the model. \n",
    "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ak_TMAzGOIFq"
   },
   "source": [
    "## Build a linear regression model as a baseline\n",
    "\n",
    "Before creating a deep neural net, find a [baseline](https://developers.google.com/machine-learning/glossary/#baseline) loss by running a simple linear regression model that uses the feature layer you just created. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "QF0BFRXTOeR3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the plot_the_loss_curve function.\n"
     ]
    }
   ],
   "source": [
    "#@title Define the plotting function.\n",
    "\n",
    "def plot_the_loss_curve(epochs, mse):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Mean Squared Error\")\n",
    "\n",
    "  plt.plot(epochs, mse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
    "  plt.show()  \n",
    "\n",
    "print(\"Defined the plot_the_loss_curve function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "RW4Qe710LgnG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the create_model and train_model functions.\n"
     ]
    }
   ],
   "source": [
    "#@title Define functions to create and train a linear regression model\n",
    "def create_model(my_learning_rate, feature_layer):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Add the layer containing the feature columns to the model.\n",
    "  model.add(feature_layer)\n",
    "\n",
    "  # Add one linear layer to the model to yield a simple linear regressor.\n",
    "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
    "\n",
    "  # Construct the layers into a model that TensorFlow can execute.\n",
    "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "  return model           \n",
    "\n",
    "\n",
    "def train_model(model, dataset, epochs, batch_size, label_name):\n",
    "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "  # Split the dataset into features and label.\n",
    "  features = {name:np.array(value) for name, value in dataset.items()}\n",
    "  label = np.array(features.pop(label_name))\n",
    "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True)\n",
    "\n",
    "  # Get details that will be useful for plotting the loss curve.\n",
    "  epochs = history.epoch\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  rmse = hist[\"mean_squared_error\"]\n",
    "\n",
    "  return epochs, rmse   \n",
    "\n",
    "print(\"Defined the create_model and train_model functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f47LmxF5X_pu"
   },
   "source": [
    "Run the following code cell to invoke the the functions defined in the preceding two code cells. (Ignore the warning messages.)\n",
    "\n",
    "**Note:** Because we've scaled all the input data, **including the label**, the resulting loss values will be *much less* than previous models. \n",
    "\n",
    "**Note:** Depending on the version of TensorFlow, running this cell might generate WARNING messages. Please ignore these warnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tsfE4ujDL4ju"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "Train on 17000 samples\n",
      "Epoch 1/15\n",
      "17000/17000 [==============================] - 0s 20us/sample - loss: 0.9933 - mean_squared_error: 0.9933\n",
      "Epoch 2/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.6857 - mean_squared_error: 0.6857\n",
      "Epoch 3/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.5245 - mean_squared_error: 0.5245\n",
      "Epoch 4/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.4317 - mean_squared_error: 0.4317\n",
      "Epoch 5/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3852 - mean_squared_error: 0.3852\n",
      "Epoch 6/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3676 - mean_squared_error: 0.3676\n",
      "Epoch 7/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3626 - mean_squared_error: 0.3626\n",
      "Epoch 8/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3605 - mean_squared_error: 0.3605\n",
      "Epoch 9/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3601 - mean_squared_error: 0.3601\n",
      "Epoch 10/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3599 - mean_squared_error: 0.3599\n",
      "Epoch 11/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3598 - mean_squared_error: 0.3598\n",
      "Epoch 12/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3598 - mean_squared_error: 0.3598\n",
      "Epoch 13/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3596 - mean_squared_error: 0.3596\n",
      "Epoch 14/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3599 - mean_squared_error: 0.3599\n",
      "Epoch 15/15\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3598 - mean_squared_error: 0.3598\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluate the linear regression model against the test set:\n",
      "3000/3000 [==============================] - 0s 33us/sample - loss: 0.3961 - mean_squared_error: 0.3961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3960839509963989, 0.39608395]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.01\n",
    "epochs = 15\n",
    "batch_size = 1000\n",
    "label_name = \"median_house_value\"\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, my_feature_layer)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "epochs, mse = train_model(my_model, train_df_norm, epochs, batch_size, label_name)\n",
    "plot_the_loss_curve(epochs, mse)\n",
    "\n",
    "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
    "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
    "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
    "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3014ezH3C7jT"
   },
   "source": [
    "## Define a deep neural net model\n",
    "\n",
    "The `create_model` function defines the topography of the deep neural net, specifying the following:\n",
    "\n",
    "* The number of [layers](https://developers.google.com/machine-learning/glossary/#layer) in the deep neural net.\n",
    "* The number of [nodes](https://developers.google.com/machine-learning/glossary/#node) in each layer.\n",
    "\n",
    "The `create_model` function also defines the [activation function](https://developers.google.com/machine-learning/glossary/#activation_function) of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "pedD5GhlDC-y"
   },
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate, my_feature_layer):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Add the layer containing the feature columns to the model.\n",
    "  model.add(my_feature_layer)\n",
    "\n",
    "  # Describe the topography of the model by calling the tf.keras.layers.Dense\n",
    "  # method once for each layer. We've specified the following arguments:\n",
    "  #   * units specifies the number of nodes in this layer.\n",
    "  #   * activation specifies the activation function (Rectified Linear Unit).\n",
    "  #   * name is just a string that can be useful when debugging.\n",
    "\n",
    "  # Define the first hidden layer with 20 nodes.   \n",
    "  model.add(tf.keras.layers.Dense(units=20, \n",
    "                                  activation='relu', \n",
    "                                  name='Hidden1'))\n",
    "  \n",
    "  # Define the second hidden layer with 12 nodes. \n",
    "  model.add(tf.keras.layers.Dense(units=12, \n",
    "                                  activation='relu', \n",
    "                                  name='Hidden2'))\n",
    "  \n",
    "  # Define the output layer.\n",
    "  model.add(tf.keras.layers.Dense(units=1,  \n",
    "                                  name='Output'))                              \n",
    "  \n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "anH4A_yCcZx2"
   },
   "source": [
    "## Define a training function\n",
    "\n",
    "The `train_model` function trains the model from the input features and labels. The [tf.keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit) method performs the actual training. The `x` parameter of the `fit` method is very flexible, enabling you to pass feature data in a variety of ways. The following implementation passes a Python dictionary in which:\n",
    "\n",
    "* The *keys* are the names of each feature (for example, `longitude`, `latitude`, and so on).\n",
    "* The *value* of each key is a NumPy array containing the values of that feature. \n",
    "\n",
    "**Note:** Although you are passing *every* feature to `model.fit`, most of those values will be ignored. Only the features accessed by `my_feature_layer` will actually be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4jv_lJYTcrEF"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataset, epochs, label_name,\n",
    "                batch_size=None):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  # Split the dataset into features and label.\n",
    "  features = {name:np.array(value) for name, value in dataset.items()}\n",
    "  label = np.array(features.pop(label_name))\n",
    "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True) \n",
    "\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "  \n",
    "  # To track the progression of training, gather a snapshot\n",
    "  # of the model's mean squared error at each epoch. \n",
    "  hist = pd.DataFrame(history.history)\n",
    "  mse = hist[\"mean_squared_error\"]\n",
    "\n",
    "  return epochs, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-IXYVfvM4gD"
   },
   "source": [
    "## Call the functions to build and train a deep neural net\n",
    "\n",
    "Okay, it is time to actually train the deep neural net.  If time permits, experiment with the three hyperparameters to see if you can reduce the loss\n",
    "against the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "nj3v5EKQFY8s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17000 samples\n",
      "Epoch 1/20\n",
      "17000/17000 [==============================] - 0s 22us/sample - loss: 0.5764 - mean_squared_error: 0.5764\n",
      "Epoch 2/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3637 - mean_squared_error: 0.3637\n",
      "Epoch 3/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3423 - mean_squared_error: 0.3423\n",
      "Epoch 4/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3379 - mean_squared_error: 0.3379\n",
      "Epoch 5/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3356 - mean_squared_error: 0.3356\n",
      "Epoch 6/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3347 - mean_squared_error: 0.3347\n",
      "Epoch 7/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3351 - mean_squared_error: 0.3351\n",
      "Epoch 8/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3322 - mean_squared_error: 0.3322\n",
      "Epoch 9/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3320 - mean_squared_error: 0.3320\n",
      "Epoch 10/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3306 - mean_squared_error: 0.3306\n",
      "Epoch 11/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3321 - mean_squared_error: 0.3321\n",
      "Epoch 12/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3303 - mean_squared_error: 0.3303\n",
      "Epoch 13/20\n",
      "17000/17000 [==============================] - ETA: 0s - loss: 0.3253 - mean_squared_error: 0.32 - 0s 4us/sample - loss: 0.3292 - mean_squared_error: 0.3292\n",
      "Epoch 14/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3292 - mean_squared_error: 0.3292\n",
      "Epoch 15/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3282 - mean_squared_error: 0.3282\n",
      "Epoch 16/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3277 - mean_squared_error: 0.3277\n",
      "Epoch 17/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3261 - mean_squared_error: 0.3261\n",
      "Epoch 18/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3261 - mean_squared_error: 0.3261\n",
      "Epoch 19/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3255 - mean_squared_error: 0.3255\n",
      "Epoch 20/20\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3252 - mean_squared_error: 0.3252\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluate the new model against the test set:\n",
      "3000/3000 [==============================] - 0s 36us/sample - loss: 0.3652 - mean_squared_error: 0.3652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3652358452479045, 0.36523584]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "batch_size = 1000\n",
    "\n",
    "# Specify the label\n",
    "label_name = \"median_house_value\"\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, my_feature_layer)\n",
    "\n",
    "# Train the model on the normalized training set. We're passing the entire\n",
    "# normalized training set, but the model will only use the features\n",
    "# defined by the feature_layer.\n",
    "epochs, mse = train_model(my_model, train_df_norm, epochs, \n",
    "                          label_name, batch_size)\n",
    "plot_the_loss_curve(epochs, mse)\n",
    "\n",
    "# After building a model against the training set, test that model\n",
    "# against the test set.\n",
    "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
    "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlPXK-SmmjQ2"
   },
   "source": [
    "## Task 1: Compare the two models\n",
    "\n",
    "How did the deep neural net perform against the baseline linear regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "hI7ojsL7nnBE"
   },
   "outputs": [],
   "source": [
    "#@title Double-click to view a possible answer\n",
    "\n",
    "# Assuming that the linear model converged and\n",
    "# the deep neural net model also converged, please \n",
    "# compare the test set loss for each.\n",
    "# In our experiments, the loss of the deep neural \n",
    "# network model was consistently lower than \n",
    "# that of the linear regression model, which \n",
    "# suggests that the deep neural network model \n",
    "# will make better predictions than the \n",
    "# linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5IKmk7D49_n"
   },
   "source": [
    "## Task 2: Optimize the deep neural network's topography\n",
    "\n",
    "Experiment with the number of layers of the deep neural network and the number of nodes in each layer.  Aim to achieve both of the following goals:\n",
    "\n",
    "*  Lower the loss against the test set.\n",
    "*  Minimize the overall number of nodes in the deep neural net. \n",
    "\n",
    "The two goals may be in conflict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "wYG5qXpP5a9n"
   },
   "outputs": [],
   "source": [
    "#@title Double-click to view a possible answer\n",
    "\n",
    "# Many answers are possible.  We noticed the \n",
    "# following trends:\n",
    "#   * Two layers outperformed one layer, but \n",
    "#     three layers did not perform significantly \n",
    "#     better than two layers; two layers \n",
    "#     outperformed one layer.\n",
    "#     In other words, two layers seemed best. \n",
    "#   * Setting the topography as follows produced \n",
    "#     reasonably good results with relatively few \n",
    "#     nodes:\n",
    "#       * 10 nodes in the first layer.\n",
    "#       *  6 nodes in the second layer.\n",
    "#     As the number of nodes in each layer dropped\n",
    "#     below the preceding, test loss increased.  \n",
    "#     However, depending on your application, hardware\n",
    "#     constraints, and the relative pain inflicted \n",
    "#     by a less accurate model, a smaller network \n",
    "#     (for example, 6 nodes in the first layer and \n",
    "#     4 nodes in the second layer) might be \n",
    "#     acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pu7R_ZpDopIj"
   },
   "source": [
    "## Task 3: Regularize the deep neural network (if you have enough time)\n",
    "\n",
    "Notice that the model's loss against the test set is *much higher* than the loss against the training set.  In other words, the deep neural network is [overfitting](https://developers.google.com/machine-learning/glossary/#overfitting) to the data in the training set.  To reduce overfitting, regularize the model.  The course has suggested several different ways to regularize a model, including:\n",
    "\n",
    "  * [L1 regularization](https://developers.google.com/machine-learning/glossary/#L1_regularization)\n",
    "  * [L2 regularization](https://developers.google.com/machine-learning/glossary/#L2_regularization)\n",
    "  * [Dropout regularization](https://developers.google.com/machine-learning/glossary/#dropout_regularization)\n",
    "\n",
    "Your task is to experiment with one or more regularization mechanisms to bring the test loss closer to the training loss (while still keeping test loss relatively low).  \n",
    "\n",
    "**Note:** When you add a regularization function to a model, you might need to tweak other hyperparameters. \n",
    "\n",
    "### Implementing L1 or L2 regularization\n",
    "\n",
    "To use L1 or L2 regularization on a hidden layer, specify the `kernel_regularizer` argument to [tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense). Assign one of the following methods to this argument:\n",
    "\n",
    "* `tf.keras.regularizers.l1` for L1 regularization\n",
    "* `tf.keras.regularizers.l2` for L2 regularization\n",
    "\n",
    "Each of the preceding methods takes an `l` parameter, which adjusts the [regularization rate](https://developers.google.com/machine-learning/glossary/#regularization_rate). Assign a decimal value between 0 and 1.0 to `l`; the higher the decimal, the greater the regularization. For example, the following applies L2 regularization at a strength of 0.05. \n",
    "\n",
    "```\n",
    "model.add(tf.keras.layers.Dense(units=20, \n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "                                name='Hidden1'))\n",
    "```\n",
    "\n",
    "### Implementing Dropout regularization\n",
    "\n",
    "You implement dropout regularization as a separate layer in the topography. For example, the following code demonstrates how to add a dropout regularization layer between the first hidden layer and the second hidden layer:\n",
    "\n",
    "```\n",
    "model.add(tf.keras.layers.Dense( *define first hidden layer*)\n",
    " \n",
    "model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Dense( *define second hidden layer*)\n",
    "```\n",
    "\n",
    "The `rate` parameter to [tf.keras.layers.Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) specifies the fraction of nodes that the model should drop out during training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "tflt9TZEDARW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17000 samples\n",
      "Epoch 1/140\n",
      "17000/17000 [==============================] - 0s 23us/sample - loss: 1.7565 - mean_squared_error: 0.6700\n",
      "Epoch 2/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.7499 - mean_squared_error: 0.4135\n",
      "Epoch 3/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.5529 - mean_squared_error: 0.3918\n",
      "Epoch 4/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4872 - mean_squared_error: 0.3795\n",
      "Epoch 5/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4602 - mean_squared_error: 0.3738\n",
      "Epoch 6/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4486 - mean_squared_error: 0.3728\n",
      "Epoch 7/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4417 - mean_squared_error: 0.3716\n",
      "Epoch 8/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4368 - mean_squared_error: 0.3706\n",
      "Epoch 9/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4339 - mean_squared_error: 0.3692\n",
      "Epoch 10/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4357 - mean_squared_error: 0.3742\n",
      "Epoch 11/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4311 - mean_squared_error: 0.3711\n",
      "Epoch 12/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4275 - mean_squared_error: 0.3677\n",
      "Epoch 13/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4247 - mean_squared_error: 0.3675\n",
      "Epoch 14/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4213 - mean_squared_error: 0.3638\n",
      "Epoch 15/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4212 - mean_squared_error: 0.3654\n",
      "Epoch 16/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4217 - mean_squared_error: 0.3658\n",
      "Epoch 17/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4185 - mean_squared_error: 0.3640\n",
      "Epoch 18/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4151 - mean_squared_error: 0.3612\n",
      "Epoch 19/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4153 - mean_squared_error: 0.3619\n",
      "Epoch 20/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4130 - mean_squared_error: 0.3597\n",
      "Epoch 21/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4119 - mean_squared_error: 0.3592\n",
      "Epoch 22/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4135 - mean_squared_error: 0.3619\n",
      "Epoch 23/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4154 - mean_squared_error: 0.3631\n",
      "Epoch 24/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4094 - mean_squared_error: 0.3587\n",
      "Epoch 25/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4086 - mean_squared_error: 0.3579\n",
      "Epoch 26/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4077 - mean_squared_error: 0.3567\n",
      "Epoch 27/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4094 - mean_squared_error: 0.3593\n",
      "Epoch 28/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4066 - mean_squared_error: 0.3577\n",
      "Epoch 29/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4052 - mean_squared_error: 0.3555\n",
      "Epoch 30/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4051 - mean_squared_error: 0.3560\n",
      "Epoch 31/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4042 - mean_squared_error: 0.3557\n",
      "Epoch 32/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4040 - mean_squared_error: 0.3559\n",
      "Epoch 33/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4037 - mean_squared_error: 0.3563\n",
      "Epoch 34/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4037 - mean_squared_error: 0.3567\n",
      "Epoch 35/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4079 - mean_squared_error: 0.3600\n",
      "Epoch 36/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4091 - mean_squared_error: 0.3629\n",
      "Epoch 37/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4007 - mean_squared_error: 0.3541\n",
      "Epoch 38/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4000 - mean_squared_error: 0.3540\n",
      "Epoch 39/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4011 - mean_squared_error: 0.3544\n",
      "Epoch 40/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4012 - mean_squared_error: 0.3553\n",
      "Epoch 41/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3996 - mean_squared_error: 0.3544\n",
      "Epoch 42/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3994 - mean_squared_error: 0.3541\n",
      "Epoch 43/140\n",
      "17000/17000 [==============================] - 0s 3us/sample - loss: 0.3980 - mean_squared_error: 0.3524\n",
      "Epoch 44/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3973 - mean_squared_error: 0.3524\n",
      "Epoch 45/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3988 - mean_squared_error: 0.3547\n",
      "Epoch 46/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3970 - mean_squared_error: 0.3529\n",
      "Epoch 47/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.4000 - mean_squared_error: 0.3554\n",
      "Epoch 48/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3990 - mean_squared_error: 0.3549\n",
      "Epoch 49/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3974 - mean_squared_error: 0.3542\n",
      "Epoch 50/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3961 - mean_squared_error: 0.3524\n",
      "Epoch 51/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3961 - mean_squared_error: 0.3536\n",
      "Epoch 52/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3959 - mean_squared_error: 0.3526\n",
      "Epoch 53/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3972 - mean_squared_error: 0.3543\n",
      "Epoch 54/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3951 - mean_squared_error: 0.3527\n",
      "Epoch 55/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3930 - mean_squared_error: 0.3508\n",
      "Epoch 56/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3930 - mean_squared_error: 0.3508\n",
      "Epoch 57/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3923 - mean_squared_error: 0.3498\n",
      "Epoch 58/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3932 - mean_squared_error: 0.3513\n",
      "Epoch 59/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3956 - mean_squared_error: 0.3535\n",
      "Epoch 60/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3934 - mean_squared_error: 0.3519\n",
      "Epoch 61/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3907 - mean_squared_error: 0.3494\n",
      "Epoch 62/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3900 - mean_squared_error: 0.3487\n",
      "Epoch 63/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3907 - mean_squared_error: 0.3496\n",
      "Epoch 64/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3907 - mean_squared_error: 0.3490\n",
      "Epoch 65/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3905 - mean_squared_error: 0.3497\n",
      "Epoch 66/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3918 - mean_squared_error: 0.3509\n",
      "Epoch 67/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3899 - mean_squared_error: 0.3493\n",
      "Epoch 68/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3890 - mean_squared_error: 0.3485\n",
      "Epoch 69/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3892 - mean_squared_error: 0.3489\n",
      "Epoch 70/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3897 - mean_squared_error: 0.3495\n",
      "Epoch 71/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3892 - mean_squared_error: 0.3491\n",
      "Epoch 72/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3887 - mean_squared_error: 0.3493\n",
      "Epoch 73/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3881 - mean_squared_error: 0.3477\n",
      "Epoch 74/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3882 - mean_squared_error: 0.3489\n",
      "Epoch 75/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3868 - mean_squared_error: 0.3480\n",
      "Epoch 76/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3887 - mean_squared_error: 0.3490\n",
      "Epoch 77/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3879 - mean_squared_error: 0.3485\n",
      "Epoch 78/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3878 - mean_squared_error: 0.3488\n",
      "Epoch 79/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3862 - mean_squared_error: 0.3477\n",
      "Epoch 80/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3864 - mean_squared_error: 0.3479\n",
      "Epoch 81/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3855 - mean_squared_error: 0.3465\n",
      "Epoch 82/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3870 - mean_squared_error: 0.3488\n",
      "Epoch 83/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3849 - mean_squared_error: 0.3473\n",
      "Epoch 84/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3888 - mean_squared_error: 0.3501\n",
      "Epoch 85/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3859 - mean_squared_error: 0.3482\n",
      "Epoch 86/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3860 - mean_squared_error: 0.3483\n",
      "Epoch 87/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3841 - mean_squared_error: 0.3461\n",
      "Epoch 88/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3834 - mean_squared_error: 0.3456\n",
      "Epoch 89/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3851 - mean_squared_error: 0.3476\n",
      "Epoch 90/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3879 - mean_squared_error: 0.3506\n",
      "Epoch 91/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3874 - mean_squared_error: 0.3501\n",
      "Epoch 92/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3859 - mean_squared_error: 0.3489\n",
      "Epoch 93/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3842 - mean_squared_error: 0.3467\n",
      "Epoch 94/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3865 - mean_squared_error: 0.3497\n",
      "Epoch 95/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3851 - mean_squared_error: 0.3485\n",
      "Epoch 96/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3822 - mean_squared_error: 0.3454\n",
      "Epoch 97/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3814 - mean_squared_error: 0.3447\n",
      "Epoch 98/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3816 - mean_squared_error: 0.3452\n",
      "Epoch 99/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3845 - mean_squared_error: 0.3480\n",
      "Epoch 100/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3837 - mean_squared_error: 0.3478\n",
      "Epoch 101/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3840 - mean_squared_error: 0.3483\n",
      "Epoch 102/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3825 - mean_squared_error: 0.3455\n",
      "Epoch 103/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3845 - mean_squared_error: 0.3487\n",
      "Epoch 104/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3836 - mean_squared_error: 0.3480\n",
      "Epoch 105/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3810 - mean_squared_error: 0.3448\n",
      "Epoch 106/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3810 - mean_squared_error: 0.3455\n",
      "Epoch 107/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3807 - mean_squared_error: 0.3449\n",
      "Epoch 108/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3800 - mean_squared_error: 0.3445\n",
      "Epoch 109/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3802 - mean_squared_error: 0.3447\n",
      "Epoch 110/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3812 - mean_squared_error: 0.3452\n",
      "Epoch 111/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3828 - mean_squared_error: 0.3478\n",
      "Epoch 112/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3802 - mean_squared_error: 0.3450\n",
      "Epoch 113/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3817 - mean_squared_error: 0.3471\n",
      "Epoch 114/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3800 - mean_squared_error: 0.3444\n",
      "Epoch 115/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3794 - mean_squared_error: 0.3454\n",
      "Epoch 116/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3812 - mean_squared_error: 0.3465\n",
      "Epoch 117/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3806 - mean_squared_error: 0.3456\n",
      "Epoch 118/140\n",
      "17000/17000 [==============================] - 0s 5us/sample - loss: 0.3799 - mean_squared_error: 0.3456\n",
      "Epoch 119/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3789 - mean_squared_error: 0.3448\n",
      "Epoch 120/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3792 - mean_squared_error: 0.3447\n",
      "Epoch 121/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3776 - mean_squared_error: 0.3436\n",
      "Epoch 122/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3787 - mean_squared_error: 0.34410s - loss: 0.3805 - mean_squared_error: 0.34\n",
      "Epoch 123/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3781 - mean_squared_error: 0.3441\n",
      "Epoch 124/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3774 - mean_squared_error: 0.3439\n",
      "Epoch 125/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3770 - mean_squared_error: 0.3425\n",
      "Epoch 126/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3776 - mean_squared_error: 0.3437\n",
      "Epoch 127/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3815 - mean_squared_error: 0.3479\n",
      "Epoch 128/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3797 - mean_squared_error: 0.3463\n",
      "Epoch 129/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3785 - mean_squared_error: 0.3453\n",
      "Epoch 130/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3792 - mean_squared_error: 0.3459\n",
      "Epoch 131/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3776 - mean_squared_error: 0.3442\n",
      "Epoch 132/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3769 - mean_squared_error: 0.3433\n",
      "Epoch 133/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3769 - mean_squared_error: 0.3435\n",
      "Epoch 134/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3778 - mean_squared_error: 0.3448\n",
      "Epoch 135/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3782 - mean_squared_error: 0.3448\n",
      "Epoch 136/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3787 - mean_squared_error: 0.3459\n",
      "Epoch 137/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3771 - mean_squared_error: 0.3443\n",
      "Epoch 138/140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3769 - mean_squared_error: 0.3439\n",
      "Epoch 139/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3777 - mean_squared_error: 0.3452\n",
      "Epoch 140/140\n",
      "17000/17000 [==============================] - 0s 4us/sample - loss: 0.3799 - mean_squared_error: 0.3469\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhc5Xn38e89o82SZdmy5VW2JYMMtsEYEIbgBLMEYkLA6UsWljTQJqVpodDSpoEkkEBKSlraJBCSliakFBpIk1JilsQhhDXEYBOMV7wbW15lyZJsa5+53z/OkRhJI3u8jEaWfp/rmsvnPOecmVsHNLee5TyPuTsiIiLdRTIdgIiI9E9KECIikpQShIiIJKUEISIiSSlBiIhIUlmZDuBYGTVqlJeVlWU6DBGR48pbb721x91Lkh0bMAmirKyMJUuWZDoMEZHjipm919sxNTGJiEhSShAiIpKUEoSIiCQ1YPogRESOVFtbG1VVVTQ3N2c6lLTJy8ujtLSU7OzslK9RghCRQa+qqorCwkLKysows0yHc8y5OzU1NVRVVVFeXp7ydWpiEpFBr7m5mZEjRw7I5ABgZowcOfKwa0hKECIiMGCTQ4cj+fmUIEREJCklCBGRfmDo0KGZDqGHQZ8gmlpjPLboPdbs3JfpUERE+pVBnyAaW9v56lMreGNTTaZDERHpYunSpZxzzjnMnDmTP/qjP2Lv3r0A3H///UyfPp2ZM2dy1VVXAfDyyy8za9YsZs2axemnn86+fUf/R++gH+YajQQdN+0xLb0qInDX0ytZtb3hmL7n9PHD+NrlMw77us9+9rM88MADzJ07lzvvvJO77rqL73znO9x7771s2rSJ3Nxc6urqALjvvvt48MEHmTNnDvv37ycvL++o4x70NYiOBBHX2twi0o/U19dTV1fH3LlzAbjuuut45ZVXAJg5cybXXnstjz32GFlZwd/5c+bM4dZbb+X++++nrq6us/xoDPoaRFYkyJHtcSUIEeGI/tLva88++yyvvPIKTz/9NPfccw/Lly/ntttu47LLLuO5555jzpw5LFy4kJNPPvmoPmfQ1yDC/EBMCUJE+pGioiJGjBjBq6++CsCjjz7K3LlzicfjbN26lQsuuIBvfetb1NfXs3//fjZs2MCpp57Kl770Jc466yzefffdo45BNYgwQyhBiEgmNTY2Ulpa2rl/66238sgjj/CFL3yBxsZGpkyZwo9//GNisRif+cxnqK+vx925+eabGT58OHfccQcvvvgikUiEGTNmcOmllx51TIM+QYRdEGpiEpGMisfjScsXLVrUo+y1117rUfbAAw8c85gGfROTmRGNGLFe/uOIiAxWgz5BAGGCyHQUIiL9S1oThJnNM7M1ZrbezG7r5ZxPmdkqM1tpZj9JKI+Z2dLwtSCdcWapBiEy6PkAH+p+JD9f2vogzCwKPAhcDFQBi81sgbuvSjinArgdmOPue81sdMJbNLn7rHTFlyhqpj4IkUEsLy+PmpqaATvld8d6EIf78Fw6O6lnA+vdfSOAmT0BzAdWJZzzZ8CD7r4XwN13pzGeXkWjRlwJQmTQKi0tpaqqiurq6kyHkjYdK8odjnQmiAnA1oT9KuDsbudMBTCz3wFR4Ovu/qvwWJ6ZLQHagXvd/anuH2BmNwA3AEyaNOmIA82KqAYhMphlZ2cf1kprg0Wmh7lmARXA+UAp8IqZnerudcBkd99mZlOA35rZcnffkHixuz8EPARQWVl5xN/wETM9ByEi0k06O6m3ARMT9kvDskRVwAJ3b3P3TcBagoSBu28L/90IvAScnq5Ag05qJQgRkUTpTBCLgQozKzezHOAqoPtopKcIag+Y2SiCJqeNZjbCzHITyufQte/imIpGlSBERLpLWxOTu7eb2U3AQoL+hYfdfaWZ3Q0scfcF4bFLzGwVEAO+6O41ZnYu8O9mFidIYvcmjn461jSKSUSkp7T2Qbj7c8Bz3cruTNh24NbwlXjO68Cp6YwtUTRixAb4GGgRkcOlJ6kJJuyLacEgEZEulCCAiIa5ioj0oARBMIpJK8qJiHSlBEHQB6EahIhIV0oQoOm+RUSSUIKgI0GoBiEikkgJAj1JLSKSjBIE6oMQEUlGCYIgQWi6bxGRrpQg0HTfIiLJKEGg6b5FRJJRggCyNJuriEgPShBANBJRghAR6UYJAoga6oMQEelGCQLVIEREklGCQA/KiYgkowSBpvsWEUlGCQJN9y0ikowSBOFUGzHN5ioikkgJAs3mKiKSjBIEYSe1mphERLpIa4Iws3lmtsbM1pvZbb2c8ykzW2VmK83sJwnl15nZuvB1XTrjVA1CRKSnrHS9sZlFgQeBi4EqYLGZLXD3VQnnVAC3A3Pcfa+ZjQ7Li4GvAZWAA2+F1+5NR6ya7ltEpKd01iBmA+vdfaO7twJPAPO7nfNnwIMdX/zuvjss/wjwvLvXhseeB+alK9BoxHBHU36LiCRIZ4KYAGxN2K8KyxJNBaaa2e/MbJGZzTuMazGzG8xsiZktqa6uPuJAsyIGoH4IEZEEme6kzgIqgPOBq4H/MLPhqV7s7g+5e6W7V5aUlBxxEJGOBKEahIhIp3QmiG3AxIT90rAsURWwwN3b3H0TsJYgYaRy7TGTpQQhItJDOhPEYqDCzMrNLAe4CljQ7ZynCGoPmNkogianjcBC4BIzG2FmI4BLwrK0iEaC26COahGR96VtFJO7t5vZTQRf7FHgYXdfaWZ3A0vcfQHvJ4JVQAz4orvXAJjZNwiSDMDd7l6brlijQQVCNQgRkQRpSxAA7v4c8Fy3sjsTth24NXx1v/Zh4OF0xtchGg1qEEoQIiLvy3Qndb+gPggRkZ4OmiDMLGJm5/ZVMJkStSBBtMc1YZ+ISIeDJgh3jxM8DT2gRcMahPKDiMj7UmliesHMrjQL/8wegLKiqkGIiHSXSoL4c+BnQKuZNZjZPjNrSHNcfSpi6oMQEenukKOY3L2wLwLJJE21ISLSU0rDXM3sCuC8cPcld38mfSH1vY4+iPaYEoSISIdDNjGZ2b3ALcCq8HWLmf1jugPrS1ENcxUR6SGVGsRHgVnhiCbM7BHgbYJ1HAaEqJqYRER6SPVBucQZVovSEUgmZUX0JLWISHep1CC+CbxtZi8CRtAXkXT50ONVmB/UByEikuCgCcLMIkAcOAc4Kyz+krvvTHdgfamjBhFXE5OISKeDJgh3j5vZ37v7/9Bzqu4Bo3MUk5qYREQ6pdIH8Rsz+zszm2hmxR2vtEfWh94fxaQnqUVEOqTSB/Hp8N8bE8ocmHLsw8mM92dzzXAgIiL9SCp9ELe5+0/7KJ6MUA1CRKSnVGZz/WIfxZIx6oMQEelJfRDoSWoRkWTUB4FWlBMRSSaV2VzL+yKQTFITk4hIT702MZnZ3ydsf7LbsW+mM6i+9v6KckoQIiIdDtYHcVXCdveJ+eal8uZmNs/M1pjZejPrMT2HmV1vZtVmtjR8fT7hWCyhPK0P6akGISLS08GamKyX7WT7PS82ixKsZ30xUAUsNrMF7r6q26k/dfebkrxFk7vPOtTnHAuarE9EpKeD1SC8l+1k+8nMBta7+0Z3bwWeAOYfZnx9IqolR0VEejhYgjitYw1qYGa43bF/agrvPQHYmrBfFZZ1d6WZLTOzn5vZxITyPDNbYmaLzOzjyT7AzG4Iz1lSXV2dQkjJRaNKECIi3fWaINw96u7D3L3Q3bPC7Y797GP0+U8DZe4+E3geeCTh2GR3rwSuAb5jZickifEhd69098qSkpIjDiJLfRAiIj2kumDQkdgGJNYISsOyTu5e4+4t4e4PgTMTjm0L/90IvAScnq5AI2ETk6b7FhF5XzoTxGKgwszKzSyHYFRUl9FIZjYuYfcKYHVYPsLMcsPtUcAcgvWw06KzBqEFg0REOqXyJPURcfd2M7sJWAhEgYfdfaWZ3Q0scfcFwM1mdgXQDtQC14eXTwP+3cziBEns3iSjn46ZSMQw02R9IiKJ0pYgANz9OeC5bmV3JmzfTs9nLHD310mtI/yYiZoRUxOTiEinXhNEOFqp129Mdx+WlogyJBoxdVKLiCToNUG4eyGAmX0D2AE8SvCA3LXAuN6uO15lRYyY+iBERDql0kl9hbt/3933uXuDu/+AfvrA29GIRNTEJCKSKJUEccDMrjWzqJlFzOxa4EC6A+trWRHTg3IiIglSSRDXAJ8CdoWvT4ZlA0o0ElEfhIhIglTWg9jMAGxS6i4a0XTfIiKJDlmDMLOpZvaCma0I92ea2VfTH1rfylINQkSki1SamP6D4FmFNgB3X0bXtSIGhKj6IEREukglQeS7+5vdytrTEUwmKUGIiHSVSoLYE86k6gBm9gmC5yIGFCUIEZGuUplq40bgIeBkM9sGbCJ4WG5AyYoY7ZqLSUSk00ETRLhs6F+6+4fNrACIuPu+vgmtb0XMiCk/iIh0OmiCcPeYmX0w3B5wD8clyoqaZnMVEUmQShPT22a2APgZCU9Qu/uTaYsqAzRZn4hIV6kkiDygBrgwocyBgZUgzLSinIhIglSepP6Tvggk06IR04pyIiIJDpkgzCwP+Bwwg6A2AYC7/2ka4+pzWVGjpU19ECIiHVJ5DuJRYCzwEeBloBQYcCOZIlpRTkSki1QSxInufgdwwN0fAS4Dzk5vWH1P032LiHSVSoJoC/+tM7NTgCJgdPpCyoxoJKI+CBGRBKmMYnrIzEYAdwALgKHAnWmNKgOiETSKSUQkwSFrEO7+Q3ff6+4vu/sUdx/t7v+Wypub2TwzW2Nm683stiTHrzezajNbGr4+n3DsOjNbF76uO7wf6/Bpum8Rka5SGcWUtLbg7ncf4roo8CBwMVAFLDazBe6+qtupP3X3m7pdWwx8DagkeObirfDavYeK90hpsj4Rka5SWpM64RUDLgXKUrhuNrDe3Te6eyvwBKmvTPcR4Hl3rw2TwvPAvBSvPSJKECIiXaXyoNy/JO6b2X3AwhTeewKwNWG/iuSjn640s/OAtcDfuPvWXq6d0P1CM7sBuAFg0qRJKYTUOyUIEZGuUqlBdJdP8CzEsfA0UObuMwlqCY8czsXu/pC7V7p7ZUlJyVEFoum+RUS6SqUPYjnhYkFAFCgBDtr/ENoGTEzYLw3LOrl7TcLuD4F/Srj2/G7XvpTCZx6xSETTfYuIJEplmOvHErbbgV3unsqSo4uBCjMrJ/jCvwq4JvEEMxvn7h2r010BrA63FwLfDIfXAlxCsC522gQPyilDiIh0SCVBdJ9WY5iZde64e22yi9y93cxuIviyjwIPu/tKM7sbWOLuC4CbzewKgsRTC1zf8Z5m9g2CJANwd2+fc6yoD0JEpKtUEsQfCJqK9gIGDAe2hMccmNLbhe7+HPBct7I7E7Zvp5eagbs/DDycQnzHRNSUIEREEqXSSf08cLm7j3L3kQRNTr9293J37zU5HG+iUS0YJCKSKJUEcU5YEwDA3X8JnJu+kDIjK6IFg0REEqXSxLTdzL4KPBbuXwtsT19ImRE11SBERBKlUoO4mmBo6/+Fr9Fh2YASjURwh7iShIgIkNqT1LXALQDhsNM694HXFpMVDUZmxdyJYIc4W0Rk4Ou1BmFmd5rZyeF2rpn9FlgP7DKzD/dVgH0lEg7d1UgmEZHAwZqYPg2sCbevC88dDcwFvpnmuPpcViRIEOqHEBEJHCxBtCY0JX0EeNzdY+6+mtQ6t48r0YhqECIiiQ6WIFrM7BQzKwEuAH6dcCw/vWH1PSUIEZGuDlYTuAX4OcEIpm+7+yYAM/so8HYfxNanop1NTJqPSUQEDpIg3P0N4OQk5T2mzxgIOvoglB9ERAJHsh7EgBRRDUJEpAsliFCW+iBERLpQggipk1pEpKuUhqua2blAWeL57v5faYopI5QgRES6SmXJ0UeBE4ClQCwsdmBAJQg9KCci0lUqNYhKYPpAnH8pUTQStLapBiEiEkilD2IFMDbdgWRaNLwTShAiIoFUahCjgFVm9ibQ0lHo7lekLaoM6KhBqIlJRCSQSoL4erqD6A86H5Qb2C1pIiIpS2U9iJeP9M3NbB7wXSAK/NDd7+3lvCsJpvU4y92XmFkZsJr3Z5Nd5O5fONI4UtEx3Xd7TAlCRARSG8V0DvAAMA3IIfiyP+Duww5xXRR4ELgYqAIWm9kCd1/V7bxCgnmf3uj2FhvcfVaqP8jR6lwwSE1MIiJAap3U3yNYYnQdMAT4PMEX/6HMBta7+0Z3bwWeAOYnOe8bwLeA5pQiTpPO5yDUxCQiAqT4JLW7rwei4XoQPwbmpXDZBGBrwn5VWNbJzM4AJrr7s0muLzezt83sZTP7UCpxHo1o54pymotJRARS66RuNLMcYKmZ/ROwg2MwRYeZRYB/Ba5PcngHMMnda8zsTOApM5vh7g3d3uMG4AaASZMmHVU8ndN9qw9CRARI7Yv+j8PzbgIOABOBK1O4blt4bofSsKxDIXAK8JKZbQbOARaYWaW7t7h7DYC7vwVsAKZ2/wB3f8jdK929sqSkJIWQetfRB6FRTCIigVRGMb1nZkOAce5+12G892KgwszKCRLDVcA1Ce9bT/CMBQBm9hLwd+EophKg1t1jZjYFqAA2HsZnH7aOJiY9ByEiEjhkDcLMLieYh+lX4f4sM1twqOvcvZ2g1rGQYMjq/7j7SjO728wO9ZDdecAyM1tKMPz1C+5ee6jPPBqarE9EpKtUH5SbDbwE4O5Lw1rBISVbfc7d7+zl3PMTtv8X+N9UPuNYydJcTCIiXaTSB9EWNgclGnDfomF+UBOTiEgolRrESjO7BoiaWQVwM/B6esPqe6pBiIh0lUoN4q+AGQQT9T0ONAB/nc6gMkF9ECIiXaUyiqkR+Er4GrCUIEREuuo1QRxqpNLAm+5bw1xFRBIdrAbxAYKpMh4nmEjP+iSiDOmc7lsJQkQEOHiCGEswE+vVBA+4PQs87u4r+yKwvqYahIhIV712UocT8/3K3a8jmAZjPcG0GDf1WXR96P0+CE3WJyICh+ikNrNc4DKCWkQZcD/wf+kPq++9P5trhgMREeknDtZJ/V8Ek+k9B9zl7iv6LKoMiEQMM9UgREQ6HKwG8RmC2VtvAW426+yjNsAPtaLc8SgrYuqDEBEJ9Zog3P2o13w43kQjphXlRERCgy4JHEzUjJgWDBIRAZQguoiqiUlEpJMSRIKsaEQryomIhJQgEkRMNQgRkQ5KEAkKcqPUN7VlOgwRkX5BCSLBiSVDWb9rf6bDEBHpF5QgElSMKWTjnv206XFqEREliEQnjR1KW8x5r+ZApkMREck4JYgEFaMLAVizU81MIiJpTRBmNs/M1pjZejO77SDnXWlmbmaVCWW3h9etMbOPpDPODieOHkrEYO2ufX3xcSIi/dohlxw9UmYWBR4kWFOiClhsZgvcfVW38woJ5nt6I6FsOnAVwVrY44HfmNlUd4+lK16AvOwok0cWsG63EoSISDprELOB9e6+0d1bgSeA+UnO+wbwLaA5oWw+8IS7t7j7JoK1KGanMdZOFaOHsmanEoSISDoTxASCJUs7VIVlnczsDGCiuz97uNeG199gZkvMbEl1dfUxCXrqmEI21zTS0p7WyoqISL+XsU5qM4sA/wr87ZG+h7s/5O6V7l5ZUlJyTOKqGDOUWNzZtEcjmURkcEtngtgGTEzYLw3LOhQSLEj0kpltJljWdEHYUX2oa9PmpLHBSKa1emBORAa5dCaIxUCFmZWbWQ5Bp/OCjoPuXu/uo9y9zN3LgEXAFe6+JDzvKjPLNbNyoAJ4M42xdiofVUA0YqxVP4SIDHJpG8Xk7u1mdhOwEIgCD7v7SjO7G1ji7gsOcu1KM/sfYBXQDtyY7hFMHXKzopSNzNdQVxEZ9NKWIADc/TmCNa0Ty+7s5dzzu+3fA9yTtuAO4pQJRfxufQ3xuBOJ2KEvEBEZgPQkdRIXnDSaPftbWLatPtOhiIhkjBJEEnOnlhAxeGH1rkyHIiKSMUoQSYwoyKFycjG/Wb0706GIiGSMEkQvLpo2mtU7Gthe15TpUEREMkIJohcXTRsDwAvvqhYhIoOTEkQvTigpYPLIfPVDiMigpQTRCzPj4mljeH19jabdEJFBSQniIP7svCnkZkf48pPLcfdMhyMi0qeUIA5izLA8vvzRafx+Yw0/W1KV8nVKJiIyEChBHMKnKydydnkx33hmFfctXMNb79USi/eeAH66eAuz7n6eZ5Zt78MoRUSOPRsof+1WVlb6kiVL0vLeW2sb+eLP32Hx5r3E4s6I/GzmTi3hgpNHM3dqCcPzcwBYtb2Bj3//d0QMmtvi3HJRBbdcVKHpOkSk3zKzt9y9MtmxtM7FNFBMLM7niRs+QH1jG6+sq+bFd3fz0tpqnlq6nYjB2eUjmT9rPA+9spER+dk8deMc7lu4lu++sI7tdU3ce+VMokoSInKcUYI4DEX52Vx+2nguP208sbjzTlUdL767m2eW7eC2J5cTMfjvz5/DuKIh3PfJmUwYMYT7X1jHgdZ2br90Gvk5UYoLcjBTshCR/k9NTMeAu7N0ax3NbXE+cMLILsd++OpG/uHZ1Z37Z5cX86Prz2Jobtfc3BaLkx1Vl5CI9K2DNTEpQfSBt97by8bq/Wyva+b+367j9InDuffKmSxYuo1fr9rFtr1N7G9t5/KZ4/nrD1cwpWRopkMWkUFCCaIfeW75Dv7q8beJxR0zOPeEkZxYMhQHfrakipb2GDecdwJ/e8nUlGoUDc1tvLZuD6dOKGJicX76fwCgsbWdqr1NTB1T2CefJyLpo07qfuSjp45jSHaUt97by6fPmtjlS/3miyr451+t4d9e3sCSzbVcNnMcK7c3MHxINjdecCIjCnI6z91a28hdT6/k5bXVtMWcCcOH8NSNcygpzE1r/Buq9/Pnj77Fxur9PH/rXE5QbUdkwFINoh/6xdJtfPnJ5RxojTGyIIe6pjYK87L4y/NP4LTS4VTvbwmf7oarz57E9HHDuO3JZUwbN4zH/+wc8rKjPd6zsbWdIdnRo+og/+27u7jl8aVkZ0XY19zGZ86ZzNcun3E0P6qIZJiamI5DdY2ttLTHGV2Yy9pd+7nzFyt4Y1Nt5/FTJxTxvWtOZ/LIAgB+tWIHX3jsD8wYP4y5U0uYXV7MuSeMAuBffr2Gh17dyIklQ/nsByZz5Zml5OccXuXxJ29s4atPLWf6+GH8+x9X8q1fvsuLa3bzxpcvOuz3EpH+QwliAHB3qvY2sWnPAeqb2rhkxhhys7rWFP5nyVYeW/Qeq7Y30B53ioZkM7Igh417DnDFaePZtOcAy7fVM74oj69dMYOLp41hR0MzDU1tjMjPoTAvi6a2GAda2tlR38yO+ia21zWzZuc+FryznQtOKuF715xBQW4WSzbX8ol/+z3f/KNTuebsSRm6KyJytJQgBpmm1hivb9jDM8t2sGbnPv7m4qlcPH0M7s4bm2r52i9WsmbXPnKiEVpj8UO+3/D8bOafNp47PjadrLDj3N356P2v4e48deMccqIRag60snVvI0u31LFoYw2tsTizy4s5feIIxhXlMWZYHkNyejZ/vbuzgea2OLMmDsfd+dmSKn7y5hZGDc1hYnE+08YN49QJRZw0prDXp9LdnR31zYwdlqcn10UOQ8YShJnNA74LRIEfuvu93Y5/AbgRiAH7gRvcfZWZlQGrgTXhqYvc/QsH+ywliNS1xeI8/uYWttY2UjaqgOFDcqhramVfc9BPUZCbxZhhuYwfPoRxRXm9NiE9/uYWbn9yedJjk4rzyc2KsG73/s6yrIjxsZnj+NwHpzClpICW9jjffn4tj73xHu4wu6yYgtwoL66p5uSxwQipLbWNNLbGAKgYPZSbLjyR0YV5LFy5kz37W6icPILCvGx+/PomVmxr4MTRQ/mTOWVceUZp0r6YROt37+dHr21i2rhCrjyjlIJcNZXJ4JORBGFmUWAtcDFQBSwGrnb3VQnnDHP3hnD7CuAv3X1emCCecfdTUv08JYi+1xaL87MlVextbKWlLcbIoblMGD6E6eOHMX74EAD27G9h1fYGqve1sHxbPT9bspUD4Rc+QMTg+nPLmVg8hH9/eSN7G1v50ryTuf7cMiIRIx53NtUc4K3Ne/nRa5tYs2sfALlZEUYW5LC9vhmAKSUFzD9tAr9etZOV2xsYMyyXmy+q4JLpY4lGjKG5WeRkBbWf2gOt/Oi1jTz0ysbw53AK87L4i/NP4IYPTemsJR1Kc1sMM3o09YkcTzKVID4AfN3dPxLu3w7g7v/Yy/lXA59190uVIAau+qY2frl8B/VNbcQdPlQxilMmFAHQ2h4nFvekzVAA8bjz0trdtLTFOW9qCQW5WVTtbWRXQzOnTxxBJGK4O7/fWMN9C9fwhy11ndfmZEU4Y9JwioZk8+K71bTG4vy/MyZw+6XT2Lq3ke+/uJ7frN7NGZOG8/UrZjB93DAiZqzZtY81O/cxaWQ+J4waSlVdIyu21fPC6t28vLaanKwIV501katnT6J8VEHnKLHW9jhVexup2ttETlaEUUNzyY4aB1piFBfkMLYor9d71PE7eTQjzpZV1fH4m1v4VOVETp80IqVrnlm2nW88s4qC3CymjCpgdnkxF08fS/mogs5zqve1sHhzLWeVFad9SLX0jUwliE8A89z98+H+HwNnu/tN3c67EbgVyAEudPd1YYJYSVADaQC+6u6vJvmMG4AbACZNmnTme++9l5afRY4/7s5r6/ewac8B3IPnRhZtqmF3QwsfmzmeT581kZPGFnY5f8E727njqRU0NLeTmxUhPyfK3sa2pO8/dlge804Zy579LfxyxU5icae4IIfyUQXsrG9me30Tvf1qmcGHp41h7tQSXllbzeLNtZw0tpDZZcVs2HOAV9dW0x53JhXnk58Tpa6xDQzOqyjh3BNGEjGjNRancvIIRg/Lo2pvI/f+8l32NrbyiTNLaWhq555nV3f2L51/UgmTi/OJuXPhyaO58OQxXeKJx51v/2YtD/x2PTNLixhfNIR1u/exoTpYSXF2eTFfv3wGTW0x/uKxt9i9rwUzOKusmHs+fgoVvTwwubuhmZfXVjMkJ0pWxHivppEd9c18srKUGeOLaG6LcdfTq1i1o4Hp43ErzzEAAAytSURBVAo5r6KES08dd7j/qYnFnTc21XBWWXHGp6uJx50X3t3NmZNHUJzw3FK6ufsR/0HRrxNEwvnXAB9x9+vMLBcY6u41ZnYm8BQwo6M5KhnVIORYqN7Xwu/W72HFtnrqm9o4e8pITpkwjK21TWys3s/4sAmtfGRBZ2f49romXnh3N8u21rGltpHxw4cwsTifycX5TCzOpy0Wp3pfC7G4k58TZcX2en7yxhb2NrYxZlgu554wirW79rFqRwMlQ3M5b2oJhXlZbK1tpKktxoj8HBrDgQfNbe8PKohY8OX9ztZ6AEoKc9lS2wjAhSeP5hsfP4Wn3t7GI69vpiWsne1vaeeCk0r487knUDF6KGt27uObv1zNim0NfLpyInd/fEZnk9nW2kZ+tWIn339pPfVNbUQjxriiIXzt8uks31bPY4u20NIW4/ufOYMPVZR0uY+vrqvmlieWUnugtUt5dtSImPHVy6bx9LIdvLmpljMnj2D97v3UN7Xxp3PK+epl01IeaLC9rom//ulS3txUS+XkEXzvmjPYva+Zf164hvFFQ7jz8umdfUst7TGWbN7L8m31VIweyumTRlA0JBvgmM22fM+zq/iPVzeRlx3hk2dO5OOnT+C00iKiEWPP/lYiBiOHpl7zam6L0dDUxuhhyWuc63fv5wcvbcAM7vvkaUcU8/HSxBQB9rp7UZJjLwF/5+69ZgAlCDmeNLfF2FLbyIklQzu/DA/1MGNzW4yV2+vJigR/JT+/ahfPLd/B1DGF3HH5dMYNy+P3G2uob2pj3oyxPb5kW9vjPPL6Zr77wjr2t7R3lk8YPoS/n3cSV5w2Puln1zW28p3frKP2QCt3z5/Ruf7JtromPvefi1m3ez9zThzF9HHDcJyN1Qf4zepdVIweyj994jQKcqK0tMc7k+XNj7/N6xtqyI4a933yNObPmkAs7tzz7Goe/t0mzi4vJitqbN7TyNiiPCpGD6V0xBDGFg0hO2o0NLVRvb+VLTUHeHFNNe2xOJ85ZzKPLnqPqBn7WtoZnp9NQ1Mbk0cWcM3sSSzaWMPrG2poaov1+PkAxhflUVlWzJSSArIixoiCHC44aTTjhw/B3dmzvxXHyYlGyMmKkB2NkBWxLvfrsUXv8dWnVvCJM0uJGDz19nZaY3GG5maRHTX2NraRFTE+fvoEPv+hck4aU9jl+t37mlm4Yic7G5pxD778X123h6a2GB+qGMVnP1DGjPHDGJGfw8trq3nyD1U8v3oXuVkRPnP2ZL5y2bQjqkVkKkFkETQRXQRsI+ikvsbdVyacU+Hu68Lty4GvuXulmZUAte4eM7MpwKvAqe5e2+ODQkoQIqmpPdDKO1vr2LjnAHnZkZRGfPVmX3Mb9y1cw+LNe1m3ex+GUVo8hA+eOIrbLj056Qi4WNx59PebOWVCEZVlxV2O/ei1TfzgpQ2MH55H2cgCdjU0s373fmq61UQiBuOKhjBtXCFfuWw65aMKWLdrH3f8YgWzJo7gxgtOYOX2Bm554m12NbQwqTif808qYe7UEk6fFNRY3tlaR1NbjFjcWV+9nyWba9nV0NLlc8pG5lO9r6XLwIoOk0fm84kzSqkYU8iL7+7m53+oYu7UEh764zPJikbYe6CV1zfU8PqGPcTdqRhdyJbaRp5YvIXmtuAh2NPCod179reyrKqOuAe1GQNGF+Zy0bQxFBfk8MTiLT1iGzU0h09VTuRPP1jOqMOolXSXyWGuHwW+QzDM9WF3v8fM7gaWuPsCM/su8GGgDdgL3OTuK83sSuDusDxOkDiePthnKUGIZFZbLE7ULC3PoTS1xtjV0Nz5AGjRkOzOUWkH09jaTu2BVkpHpDaRZSzuxOLOltpGfr1qJ29vqWPC8CFMHplPVjRCW3uctliclvY4v99Qw+831gAwNDeLS2aM4e75p/SYyr+72gOtPLd8B4s317JyewM50QiFeVmcXV7M5aeNT9qn09oeZ/HmWt6rCQdlTBrOB08clfKIu4PRg3IiImmwpaaRbXVNnDF5+HE73FmzuYqIpMGkkflMGtk30+xngpYwExGRpJQgREQkKSUIERFJSglCRESSUoIQEZGklCBERCQpJQgREUlKCUJERJIaME9Sm1k1cDTzfY8C9hyjcNLteIoVFG+6Kd70OZ5ihSOLd7K7lyQ7MGASxNEysyW9PW7e3xxPsYLiTTfFmz7HU6xw7ONVE5OIiCSlBCEiIkkpQbzvoUwHcBiOp1hB8aab4k2f4ylWOMbxqg9CRESSUg1CRESSUoIQEZGkBn2CMLN5ZrbGzNab2W2Zjqc7M5toZi+a2SozW2lmt4TlxWb2vJmtC/8dkelYO5hZ1MzeNrNnwv1yM3sjvMc/NbOcTMfYwcyGm9nPzexdM1ttZh/o5/f2b8L/D1aY2eNmltef7q+ZPWxmu81sRUJZ0vtpgfvDuJeZ2Rn9JN5/Dv9/WGZm/2dmwxOO3R7Gu8bMPtIf4k049rdm5mY2Ktw/6vs7qBOEmUWBB4FLgenA1WY2PbNR9dAO/K27TwfOAW4MY7wNeMHdK4AXwv3+4hZgdcL+t4Bvu/uJBGuPfy4jUSX3XeBX7n4ycBpB3P3y3prZBOBmoNLdTyFY6/0q+tf9/U9gXrey3u7npUBF+LoB+EEfxZjoP+kZ7/PAKe4+E1gL3A4Q/t5dBcwIr/l++B3Sl/6TnvFiZhOBS4AtCcVHfX8HdYIAZgPr3X2ju7cCTwDzMxxTF+6+w93/EG7vI/gCm0AQ5yPhaY8AH89MhF2ZWSlwGfDDcN+AC4Gfh6f0p1iLgPOAHwG4e6u719FP720oCxhiZllAPrCDfnR/3f0VoLZbcW/3cz7wXx5YBAw3s3F9E2kgWbzu/mt3bw93FwGl4fZ84Al3b3H3TcB6gu+QPtPL/QX4NvD3QOKoo6O+v4M9QUwAtibsV4Vl/ZKZlQGnA28AY9x9R3hoJzAmQ2F19x2C/1Hj4f5IoC7hF64/3eNyoBr4cdgk9kMzK6Cf3lt33wbcR/BX4g6gHniL/nt/O/R2P4+H378/BX4ZbvfLeM1sPrDN3d/pduio4x3sCeK4YWZDgf8F/trdGxKPeTBWOePjlc3sY8Bud38r07GkKAs4A/iBu58OHKBbc1J/ubcAYdv9fILENh4oIElzQ3/Wn+7noZjZVwiaeP8707H0xszygS8Dd6bj/Qd7gtgGTEzYLw3L+hUzyyZIDv/t7k+Gxbs6qovhv7szFV+COcAVZraZoLnuQoI2/uFhkwj0r3tcBVS5+xvh/s8JEkZ/vLcAHwY2uXu1u7cBTxLc8/56fzv0dj/77e+fmV0PfAy41t9/WKw/xnsCwR8M74S/d6XAH8xsLMcg3sGeIBYDFeEokByCDqgFGY6pi7AN/0fAanf/14RDC4Drwu3rgF/0dWzdufvt7l7q7mUE9/K37n4t8CLwifC0fhErgLvvBLaa2Ulh0UXAKvrhvQ1tAc4xs/zw/4uOePvl/U3Q2/1cAHw2HG1zDlCf0BSVMWY2j6CZ9Ap3b0w4tAC4ysxyzaycoPP3zUzE2MHdl7v7aHcvC3/vqoAzwv+3j/7+uvugfgEfJRipsAH4SqbjSRLfBwmq5MuApeHrowRt+y8A64DfAMWZjrVb3OcDz4TbUwh+kdYDPwNyMx1fQpyzgCXh/X0KGNGf7y1wF/AusAJ4FMjtT/cXeJygf6Qt/LL6XG/3EzCCUYQbgOUEo7P6Q7zrCdruO37f/i3h/K+E8a4BLu0P8XY7vhkYdazur6baEBGRpAZ7E5OIiPRCCUJERJJSghARkaSUIEREJCklCBERSUoJQuQwmFnMzJYmvI7ZRH5mVpZslk6RTMk69CkikqDJ3WdlOgiRvqAahMgxYGabzeyfzGy5mb1pZieG5WVm9ttwPv4XzGxSWD4mXGvgnfB1bvhWUTP7DwvWfPi1mQ3J2A8lg54ShMjhGdKtienTCcfq3f1U4HsEs9oCPAA84sHaAv8N3B+W3w+87O6nEcz/tDIsrwAedPcZQB1wZZp/HpFe6UlqkcNgZvvdfWiS8s3Ahe6+MZxccae7jzSzPcA4d28Ly3e4+ygzqwZK3b0l4T3KgOc9WFgHM/sSkO3u/5D+n0ykJ9UgRI4d72X7cLQkbMdQP6FkkBKEyLHz6YR/fx9uv04wsy3AtcCr4fYLwF9A5xreRX0VpEiq9NeJyOEZYmZLE/Z/5e4dQ11HmNkyglrA1WHZXxGsWPdFgtXr/iQsvwV4yMw+R1BT+AuCWTpF+g31QYgcA2EfRKW778l0LCLHipqYREQkKdUgREQkKdUgREQkKSUIERFJSglCRESSUoIQEZGklCBERCSp/w/EZvAgJ5izzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluate the new model against the test set:\n",
      "3000/3000 [==============================] - 0s 45us/sample - loss: 0.4164 - mean_squared_error: 0.3832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4163517355918884, 0.38321722]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Double-click for a possible solution\n",
    "\n",
    "# The following \"solution\" uses L2 regularization to bring training loss\n",
    "# and test loss closer to each other. Many, many other solutions are possible.\n",
    "\n",
    "\n",
    "def create_model(my_learning_rate, my_feature_layer):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "\n",
    "  # Discard any pre-existing version of the model.\n",
    "  model = None\n",
    "\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Add the layer containing the feature columns to the model.\n",
    "  model.add(my_feature_layer)\n",
    "\n",
    "  # Describe the topography of the model. \n",
    "\n",
    "  # Implement L2 regularization in the first hidden layer.\n",
    "  model.add(tf.keras.layers.Dense(units=20, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.04),\n",
    "                                  name='Hidden1'))\n",
    "  \n",
    "  # Implement L2 regularization in the second hidden layer.\n",
    "  model.add(tf.keras.layers.Dense(units=12, \n",
    "                                  activation='relu', \n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.04),\n",
    "                                  name='Hidden2'))\n",
    "\n",
    "  # Define the output layer.\n",
    "  model.add(tf.keras.layers.Dense(units=1,  \n",
    "                                  name='Output'))                              \n",
    "  \n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "  return model     \n",
    "\n",
    "# Call the new create_model function and the other (unchanged) functions.\n",
    "\n",
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.007\n",
    "epochs = 140\n",
    "batch_size = 1000\n",
    "\n",
    "label_name = \"median_house_value\"\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, my_feature_layer)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "epochs, mse = train_model(my_model, train_df_norm, epochs, \n",
    "                          label_name, batch_size)\n",
    "plot_the_loss_curve(epochs, mse)\n",
    "\n",
    "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
    "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Intro to Neural Nets.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
